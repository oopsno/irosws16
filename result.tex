\section{Result}

We tested these solution on a quad-core machine (TABLE \ref{table:machine}).

\begin{table}[h]
  \renewcommand{\arraystretch}{1.3}
  \caption{Componments of the framework}
  \label{table:machine}
  \centering
  \begin{tabular}{ll}
     \hline
     \bfseries Item & \bfseries Details \\
     \hline
     CPU & Quad-core i7 \\ 
     RAM & 8 GB \\
     OS  & ArchLinux with kernel 4.3.3 \\
     ROS & ROS Indigo \\
     \hline
  \end{tabular}
\end{table} 

The benchmark is Chinese text segmentation, using the \"stutter\" framework.
Each test is using 256KB UTF-8 coded text as sample,
we emittd $100$ requires in paralall, measure the total
time cost for a single require, and calculate the average response time,
with IO cost.

\begin{table}[h]
  \renewcommand{\arraystretch}{1.3}
  \caption{Componments of the framework}
  \label{table:textseg}
  \centering
  \begin{tabular}{lll}
     \hline
     \bfseries Case & \bfseries Time Cost(Seconds) \\
     \hline
     Sigle thread, native ROS          & 62.7 \\
     Sigle thread, 4 Cells             & 28.4 \\
     4 threads per Service, 1 Cell     & 25.1 \\
     4 threads per Service, native ROS & 24.7 \\
     \hline
  \end{tabular}
\end{table} 

As each instance runs on it's own message queue,
the multi-process solution we made is significantly slower than native
multi-threaded Services, but the overhead is still acceptable comparing with
the scalability.
